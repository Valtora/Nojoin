### Database Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=nojoin
## Note: In docker-compose, the host is db. For local development outside docker, use localhost.
DATABASE_URL=postgresql://postgres:postgres@db:5432/nojoin

### Redis Configuration
REDIS_URL=redis://redis:6379/0

### Celery Configuration
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

### Frontend Configuration
## Note: The official Docker image uses a relative URL (/api) by default, so this variable
## is ignored in production Docker deployments unless you rebuild the image.
##
## Required for:
## 1. Local development (npm run dev)
## 2. Custom builds where frontend/backend are on different domains
##
## - Localhost only: https://localhost:14443/api
## - LAN Access: https://192.168.1.X:14443/api
## - Remote/Cloudflare: https://nojoin.yourdomain.com:14443/api (or correct port if proxied)
NEXT_PUBLIC_API_URL=https://localhost:14443/api

### CORS Configuration

## Comma-separated list of origins allowed to access the API.
## Required if accessing from a different domain or IP than localhost.
## Example: https://nojoin.yourdomain.com:14443,https://192.168.1.50:14443
ALLOWED_ORIGINS=

# Worker Configuration
WHISPER_ENABLE_WORD_TIMESTAMPS=true

### Security (Optional)
## A secure SECRET_KEY is automatically generated on first startup.
## Only set this manually for advanced deployments.
# SECRET_KEY=your_custom_key_here

### GPU Configuration
## Highly recommended for the Celery worker to ensure reasonable processing times for
## transcription (Whisper) and diarization (Pyannote).
## Without a GPU, processing will be significantly slower.

# NVIDIA_VISIBLE_DEVICES=all
# NVIDIA_DRIVER_CAPABILITIES=compute,utility

### Initial Setup Configuration (Optional)
### Pre-configure the system for automated deployment.
### These values will pre-fill the setup wizard.

## Hugging Face Token, be sure to accept the T&Cs on HuggingFace, see README.md for more information.

# HF_TOKEN=hf_...

## Choose your LLM provider from the list below:

# LLM_PROVIDER=gemini # gemini, openai, anthropic, ollama

## Set your LLM provider API key here:

# GEMINI_API_KEY=
# OPENAI_API_KEY=
# ANTHROPIC_API_KEY=
# OLLAMA_API_URL=http://host.docker.internal:11434
# OLLAMA_API_URL=http://host.docker.internal:11434
